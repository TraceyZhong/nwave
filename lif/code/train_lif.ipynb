{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictlearner import DictLearnerFactory\n",
    "from lif import LIFFactory\n",
    "import numpy as np\n",
    "from utils import Config, Log, mkdir\n",
    "from pallet import ImageLoader\n",
    "from vis_sc import plot_feedforward_weights, vis_error\n",
    "config = Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training from scratch\n",
    "\n",
    "This section can be used to run the training process for an experiment from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust these constants as desired!\n",
    "config = Config\n",
    "config.num_units = 1600\n",
    "config.num_euler_steps = 50\n",
    "config.emb_dim = 256\n",
    "config.WE = 8\n",
    "config.WI = 8\n",
    "config.target_l1 = 0.07\n",
    "config.VT = -0.026\n",
    "\n",
    "lif_name = \"kglight1\"\n",
    "dictlearner_name = \"globalposnormregl1\"\n",
    "\n",
    "train_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.fpath = \"./result/{}{}/\".format(lif_name, dictlearner_name)\n",
    "mkdir(config.fpath)\n",
    "logger = Log(config.fpath + \"logfile.txt\")\n",
    "config.logger = logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing loader, LIF, and dictionary learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ImageLoader(config.batch_size, config.emb_dim)\n",
    "lif = LIFFactory.registry[lif_name](config)\n",
    "lif.init_internal_state()\n",
    "dictlearner = DictLearnerFactory.registry[dictlearner_name](config, lif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = []\n",
    "records = np.empty((train_steps, 4))\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "for t in range(train_steps):\n",
    "   if t>0 and t%500 == 0:\n",
    "      print(\"At step {} out of {}, time elapsed {:.2f}s\".format(t, train_steps, time.time()))\n",
    "      dictlearner.dump(t)\n",
    "      plot_feedforward_weights(dictlearner.Phi, config.fpath, t)\n",
    "\n",
    "   batch, _ = loader.load_train_batch()\n",
    "   try: \n",
    "      record = dictlearner.train(batch, t)\n",
    "      logger.write(\"At step {} has VT {:.3e} with record\".format(t, dictlearner.lif.VT), record)\n",
    "   except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      break\n",
    "   \n",
    "   acts.append(dictlearner.acts)\n",
    "   records[t,:] = record\n",
    "\n",
    "trained_steps = t+1\n",
    "records = records[:trained_steps]\n",
    "\n",
    "lif.dump(trained_steps)\n",
    "dictlearner.dump(trained_steps)\n",
    "plot_feedforward_weights(dictlearner.Phi, config.fpath, trained_steps)\n",
    "vis_error(records, config.fpath, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
